%% PRE EDITION
\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{ucs} 
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{soul}
\usepackage[pdftex]{graphicx}

\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{thmtools}

%% CHEMICAL EQUATION
\usepackage{chemist}
\usepackage{etex}
\usepackage{m-pictex,m-ch-en}

%% LAYOUT
\declaretheoremstyle[
    bodyfont=\normalfont\color{red},
    headfont=\color{red}
]{styleattention}

\declaretheoremstyle[
    spacebelow=1em
]{styleremarque}

\declaretheoremstyle[
    spaceabove=-6pt, 
    spacebelow=6pt, 
    headfont=\normalfont\bfseries, 
    bodyfont = \normalfont,
    postheadspace=1em, 
    qed=$\Box$, 
    headpunct={$\rhd$}
]{mystyle} 

\declaretheorem[thmbox=M,numberwithin=section,title=Définition]{definition}
\declaretheorem[thmbox=M,sibling=definition]{proposition}
\declaretheorem[thmbox=M,sibling=definition]{corollaire}
\declaretheorem[thmbox=M,sibling=definition,title=Théorème]{theoreme}
\declaretheorem[thmbox=M,sibling=definition]{lemme}
\declaretheorem[thmbox=M,sibling=definition,title=Propriété]{propriete}
\declaretheorem[thmbox=M,sibling=definition,title=Propriétés]{proprietes}
\declaretheorem[style=styleremarque,sibling=definition,title=Remarque]{remarque}
\declaretheorem[style=styleattention,title=À revoir]{Arevoir}
\declaretheorem[name={}, style=mystyle, unnumbered]{preuve}


\renewcommand\qedsymbol{$\blacksquare$}

%% NEW COMMAND
\newcommand{\mass}{\mathrm{M}}
\newcommand{\pol}{a}
\newcommand{\dep}{b}
\newcommand{\Y}{\mathscr{Y}}
\newcommand{\Z}{\mathscr{Z}}
\newcommand{\yea}{y_{\epsilon, \alpha}}
\newcommand{\zea}{z_{\epsilon, \alpha}}

\usepackage{geometry}
\geometry{hmargin=3cm,vmargin=2.5cm}

\usepackage{tabularx}
\usepackage{float}

\title{Examen : Probèmes inverses et dynamique des population}
\author{Cécile Della Valle}

%% DEBUT DE REDACTION
\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Etude du problème direct}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Question 1. Positivité, borne supérieure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


 \textbf{a.} Les constantes $a$ et $b$ sont les constantes de polymérisation et de dépolymérisation. 
 Ce modèle est la limite du modèle de Becker-Döring, 
 correspondant aux réactions chimiques entre des monomères $C_1$ 
 et des polymères de taille $i>2$ noté $P_i$ :
 
\begin{equation}
    \begin{cases}
	P_{i} \; + \; C_1 \overset{a}{\longrightarrow} P_{i+1}\\
	P_{i} \overset{b}{\longrightarrow}  P_{i-1} + \;C_1
    \end{cases}
\end{equation}

Quand le nombre de polymères tend vers $+\infty$, 
on peut poser $x=\epsilon i$, 
qui permet d'adimensionner les équations détaillées. 
Enfin, en faisant tendre $\epsilon$ vers $0$,
on retrouve le système (1).

Ainsi, la quantité $c(t)$ représente 
la concentration de monomères en fonction du temps, et $u(x,t)$ la concentration de polymère de taille $x$ en fonction du temps.

Enfin, les quantités $\mu_0$ et $\mu_1$ représentent respectivement les moments d'ordre $0$ et d'ordre $1$ de la concentration des polymères au cours du temps.

\textbf{b.}
Soit $u$ solution classique du système (1), 
on pose le problème de Cauchy suivant :
\begin{equation}
\begin{cases}
	\label{eq:caract}
	\displaystyle \frac{\mathrm{d}}{\mathrm{d}s} X(t,x_0)
	= \pol c(t) - \dep 
	= v(t)\\
	X(0,t) = x_0
	\end{cases}
	\end{equation}
	
	Ce problème admet une unique solution si $v$ est de classe $C^1(\mathbb{R})$,.
	On dérive $u$ le long de la courbe caractéristique définie par $X$.
	On pose $U(X(s))=u(s, X(s,x_0))$ où l'on suppose que $u$ est une solution classique du système (1).
	Lorsque l'on dérive $U$ le long d'une courbe caractéristique on obtient :
	\[ 
	\begin{split}
		\frac{\mathrm{d}}{\mathrm{d}s} U(X(s)) & = \frac{\mathrm{d} X }{\mathrm{d}s} \frac{\partial}{\partial x}u(s,X(s,x_0)) + \frac{\partial}{\partial t}u(s,X(s,x_0)) \\
		                                 & = v(s) \frac{\partial}{\partial x} u(s,X(s,x_0)) + \frac{\partial}{\partial t} u(s,X(s,x_0))\\
										 & =0 
	\end{split}
		\]
		
	La solution classique $u$ est donc constante le long d'une courbe caractéristique et $u(s,X(s,x_0)) = u(0,x_0)=u^{in}(x_0)$.
	
	De plus on peut obtenir une expression analytique explicite de cetet courbe :
	
	\[ X(t,x_0) = x_0 + \int_0^t v(s)ds \]
	
	D'après cette expression pour tout $t>0$ et $x = x_0 + X(0,t)$ 
	alors $x \in \mathbb{R} = supp(u^{in})$. 
	Le prolongement de $u^{in}$ sur $\mathbb{R}$ nous assure que la quantité
	$u^{in}(x)$ est bien définie pour tout $t$ et $x = x_0 + X(0,t)$.
	
	Ainsi pour tout $t>0$ et toute taille 
	$x$, $u(t,x) = u^{in}(x-\int_0^t v(s)ds)\geq 0$.
	
	Cette expression nous donne l'unique solution, et puisque $u^{in}$ est continue 
	alors $u$ appartient à $L^1(\mathbb{R}^+, C_b(\mathbb{R}))$.

\textbf{c.}
Intégrer (1) contre le poids $x$ donne le système d'équation suivant :

\[	
\begin{split}
\displaystyle \frac{\mathrm{d}}{\mathrm{d} t} \int_0^{+\infty} x u(t,x)dx
	                        &= - (ac(t)-b)\int_0^{+\infty}
							x\frac{\partial}{\partial x}u(t,x)dx\\
							&= - (ac(t)-b) [
							[xu(t,x)]_0^{+\infty} 
							- \int_0^{+\infty} u(t,x)dx]\\
							& = (ac(t)-b) \int_0^{+\infty} u(t,x)dx
\end{split}
\]

On en déduit donc :
\[ \displaystyle \frac{\mathrm{d}}{\mathrm{d} t} \int_0^{+\infty} x u(t,x)dx
+ \frac{\mathrm{d}}{\mathrm{d} t} c(t) = 0 \]

Donc la quantité $\mu_1(t) +c(t) = \rho_0$ est constante au cours du temps.
Cette relation correspond à la conservation de la masse.

\textbf{d.} 
	Puisque :
	\[\displaystyle \frac{\mathrm{d}}{\mathrm{d} t} c(t) = -(ac(t)-b)\mu_0(t)\]
	Sachant que pour tout $t>0$ et pour tout $x$ on a $u(t,x)\geq 0$,
	on en déduit que de même $\mu_0(t) \geq 0$ et $\mu_1(t)\geq 0$
	Or, 
	\[ ac(t)-b = a(\rho_0 - \mu_1(t))-b = a(\rho_0)-b - a\mu_1(t) <0 \]
	Donc la fonction $c$ est strictement croissante dès que $\mu_0(t)>0$.Or, à $t=0$,   $c(0)=0$,
	donc si $\mu_0(0)>0$, pour tout $t>0$, $c(t)> 0$.

\textbf{e.}
On a d'une part pour tout $t\geq 0$, $c(t)+\mu_1(t) = \rho_0$, et d'autre part $c(t)\geq 0$ et $mu_1(t)\geq 0$.

Donc on obtient les deux inégalités :
\[
\begin{cases}
	0 \leq c(t) \leq \rho_0 \\
	0 \leq \mu_1(t) \leq \rho_0
\end{cases}
\]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Question 2. Comportement asymptotique de la solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{a.}
A $t=0$, $c(0) = 0$ donc $v(0) = ac(0) -b = -b <0$.
Or, on a démontré que :
\[\displaystyle \frac{\mathrm{d}}{\mathrm{d} t} c(t) = -(ac(t)-b)\mu_0(t)\]

Démontrons par l'absurde que la vitesse $v$ ne change pas de signe.

La vitesse $v$ est continue (et même absoluement continue)
puisque c'est une fonction intégrale d'une fonction de $L^1$.

Par le théorème des valeurs intermédiaires, si $v$ change de signe,
alors il exite $t^*>0$ tel que $v(t^*)= 0$, 
	dans ce cas $\mu_1(t^*)= \rho_0 -\dep $, 
	$\frac{\mathrm{d} v }{\mathrm{d}t} (t^*) = 0$.
	
	Si $\mu_0(t^*)>0$ alors $\forall t<t^*$, $0<\mu_0(t^*)<\mu_0(t)$ et on note $ \mu_0(t^*)= \alpha$, et il vient :
	
	\[ \frac{\mathrm{d} |v| }{\mathrm{d}t} = \mu_0(t)|v(t)| \geq \alpha |v(t)| \]
	
	Donc d'après le lemme de Grönwall :
	\[ |v(t)| \geq |v(0)| e^{-\alpha t} \]
	
	Ceci contredit le fait que $v$ s'annule en $t=t^*$.
	Donc nécessairement $\mu_0(t^*) = 0$, 
	or, $x \to xy (x,t)$ et $x \to y(x,t)$ sont des fonctions positives de même support,
	donc $\mu_1(t^*) =0 \implies \mu_0(t^*)=0$ .
	
	En effet, le système est entièrement dépolymérisé et le système vérifie :
	
	$\forall t>t^*$:  $y(x,t)=y(x,t^*)= 0$.
	
	Donc $v(t^*) = \mass - \dep - \mu_1(t^*) = \mass- \dep > 0$.
	
	C'est une contradiction.	

En utilisant maintenant l'hypothèse (2), on peut écrire 
en posant $\delta = -(\rho_0 a -b) $ et dans ce cas :
\[ ac(t)-b \leq \delta <0 \] 

Donc les courbes caractéristiques ont une pente $v$ strictement négative.

\textbf{b.}
Pour tout $t>0$, $x \in[0,+\infty)$, on a :
\[ u(x,t) = u^{in}(x- \int_0^t v(s)ds) \]

Donc pour $T = \displaystyle \frac{L}{\delta}$, et $t>T$, on a $x- \int_0^t v(s)ds > x+\delta t >L $. Or, la fonction $u^{in}$ est de support sur $[0,L]$ 
donc pour $t>T$, $u(x,t)=0$.
On a naturellement comme borne supérieure $\displaystyle \frac{L}{\delta}$.

\textbf{c.}
Par le même raisonnement, à $t>0$ fixé, 
on suppose que $supp(u^{in})= [l_1,l_2]$,
alors  d'après l'expression de $u$ issue de la méthode des caractéristiques :
\[supp (u(t,x)) = [l_1 + \int_0^t v(s) , l_2 + \int_0^t v(s) ds] \cap [0,L]\] 

\textbf{d.}
Pour $t>T$, la fonction $u(x, \cdot)=0$, 
et on a $c(t) = \rho_0 - \mu_1(t) = \rho_0$.
La fonction $c$ converge en un temps fini vers une constante.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Question 3. Equations des moments}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{a.}
Pour $k>1$ :
\[	
\begin{split}
	\displaystyle \frac{\mathrm{d}}{\mathrm{d} t} \int_0^{+\infty} x^k u(t,x)dx
	                        &= - (ac(t)-b)\int_0^{+\infty}
							x^k \frac{\partial}{\partial x}u(t,x)dx\\
							&= - (ac(t)-b) [
							[x^k u(t,x)]_0^{+\infty} 
							- \int_0^{+\infty} u(t,x)dx ]\\
							& = (ac(t)-b) \int_0^{+\infty} kx^{k-1} u(t,x)dx
\end{split}
\]

Donc $ \displaystyle \frac{\mathrm{d}}{\mathrm t}\mu_k = k (ac(t)-b) \mu_{k-1}$


\textbf{b.}
Pour $k =0$ :
\[
\begin{split}
	\displaystyle \frac{\mathrm{d}}{\mathrm{d} t} \int_0^{+\infty} u(t,x)dx
	                        &= - (ac(t)-b)\int_0^{+\infty}\frac{\partial}{\partial x}u(t,x)dx\\
							&= - (ac(t)-b) 
							[u(t,x)]_0^{+\infty} \\
							&= 	(ac(t)-b)u(t,0)
\end{split}
\]

Donc $\displaystyle \frac{\mathrm{d}}{\mathrm{d} t} \mu_0 = (ac(t)-b)u(t,0)$.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Etude du problème inverse, premier cas : $c(t)$ connu, on mesure $\mu_0$}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Question 4. Formulation du problème inverse, cadre statique}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\textbf{a}.

Soit $\Y = L^2(0,L)$ et $\Z = L^2(\mathbb{R}^+)$ deux espaces de Hilbert. 
On définit l'application $\Psi$ :

 \begin{equation}
	 \Psi \; : \; \left\vert
	\begin{array}{ccc}
	\Y & \to & \Z \\
	u^{in} & \mapsto & t \to \int_0^L u(x,t) dx\\
	\end{array} \right.
\end{equation}

Alors l'application $\Psi$ appartient à $L(\Y,\Z)$.

\begin{definition}
Le problème inverse que nous allons étudier se définit ainsi : 
étant donné $z \in \Z$, on cherche $u^{in} \in \Y$ 
tel que $\Psi u^{in} = z$.
\end{definition}

\textbf{b.}
Soit $u^{in} \in \Y$, et $t \geq 0$ :

\[ \begin{split}
\Psi u^{in}(t) &= \mu_0 (t) \\
               &= \int_0^L u(x,t) dx \\
			   &= \int_0^L u^{in}( x - a\int_0^tc(s)ds + bt) dx \\
\end{split}\]

\textbf{c.}

L'application $\Psi$ est linéaire par linéarité de l'opérateur intégrale.
De plus $\Psi $ est positive dès que $u^{in}$ l'est (d'après la question 1.b), par intégration d'une fonction positive.

Montrons que $\Psi$ est continu en montrant que $\Psi$ est borné.

Pour se faire, montrons d'apord qu'il existe $T>0$ tel que :

\[ a\int_0^Tc(s)ds - bT = L\]

Soit la fonction $Y_0$ telle que :

\[Y_0 \; : \; \left\vert
	\begin{array}{ccc}
	\mathbb{R}^+ & \to & \mathbb{R}^+\\
	t & \mapsto & -\int_0^t (ac(s)-b)ds \\
	\end{array} \right.
\]

Puisque pour tout $t \geq 0 $ on a $v(t)<0$,
alors cela implique $c(t)< \frac{b}{a}$ et alors $ac(t)-b<0$, donc $Y_0$ est une fonction strictement croissante, de plus $Y_0$ est bijective puisque sa dérivée ne s'annule pas sur $\mathbb{R}^+$, comme montré à la question 2.a..
$Y_0 (0) =0$ donc $Y_0$ est positif pour tout $t \geq 0$,
et il existe $T$ tel que $Y_0(T) = L$.

Soit $u$ l'unique solution du système (1) pour la condition initiale $u^{in}$.

On pose le changement de variable $x'=x - a\int_0^tc(s)ds + bt = x + Y_0 (t)$ il vient pour tout $t \geq 0$ :
\[ \begin{split}
\|\Psi u^{in}\|_{\Z}^2 &= \int_0^\infty |u(x,t)|^2 dx \\
			   &= \int_0^\infty \int_0^L |u^{in}( x + Y_0 (t))|^2 dx \\
			   &= \int_0^\infty \int_{Y_0}^{L} |u^{in}(x')|^2 dx' \\
			   & \leq \int_0^T \int_{Y_0}^L |u^{in}(x')|^2 dx'\\
			   & \leq T \| u^{in} \|^2
\end{split}\]
avec $T = Y_0^{-1}(L) =$ constante.

On vient donc par cette inégalité de montrer la continuité de $\Psi$. De plus la norme de $\Psi$ est majorée par $T = Y_0 ^{-1}(L)$.

\textbf{d.}
Comme précédemment, on introduit la notation $Y_0(t)= -\int_0^t v(s)ds$
Soit $u_1^{in}$, $u_2^{in}$ de $\mathscr{Y}$,
calculons la quantité :
\[
\begin{split}
	\langle \Psi u_1^{in}, \Psi u_2^in \rangle_{\mathscr{Z}}  
	                                  &= \int_{t=0}^{+\infty} 
									  (\int_{x_1=0}^L u_1(t,x_1)dx_1)
									  (\int_{x_2=0}^L u_2(t,x_2) dx_2)
									  dt\\
	                                  &= \int_{t=0}^{T} 
									  \int_{x_1=Y_0}^L \int_{x_2=0}^L
									  u_1^{in}(x_1)
									   u_2(t,x_2) 
									  dx_2dx_1dt\\
	                                  &= \int_{x_1=0}^L
									  (u_1^{in}(x_1)
									  \int_{t=0}^{Y_0^{-1}(x_1)} 
									   \int_{x_2=0}^L
									   u_2(t,x_2) 
									  dx_2 dt )dx_1\\
	                                  &= \langle u_1^{in},
									  \Psi^* \Psi u_2^{in} \rangle_{\mathscr{Y}}
\end{split}
\]

On définit donc l'adjoint :

\begin{equation}
	 \Psi^* \; : \; \left\vert
	\begin{array}{ccc}
	\Z & \to & \Y \\
	\mu_0 & \mapsto & x \to \int_0^{Y_0^{-1}(x)} \mu_0(t)dt \\
	\end{array} \right.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Question 5. Résolution "directe" du problème inverse}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{a.}
D'après la question 3.b., on a obtenu la relation, pour $\mu_0 \in \mathscr{Z}$ 
et $u^{in} \in \mathscr{Y}$ :

\[ \displaystyle \frac{\mathrm{d}}{\mathrm{d} t} \mu_0 
= (ac(t)-b)u^{in}(-\int_0^tv(s)ds)\]

Ce problème est mal posé d'ordre 1, en effet $\mu_0$ est une fonction de $L^2$ et non de $H^1$. 

\textbf{b.}
On remarque que :
\[ Y_0(t) = bt - a\int_0^t c(s)ds = -\int_0^t v(s)ds\]

Or reprend le même raisonnement qu'à la question 2.c., puisque pour tout $t \geq 0 $ on a $v(t)<0$,
alors cela implique que $Y_0$ est une fonction strictement croissante de $\mathbb{R}^+$, elle est donc bijective.
On peut donc écrire pour tout $x $ :

\[ u^{in}(x) = \displaystyle \frac{1}{v(Y_0^{-1}(x))} \frac{\mathrm{d}}{\mathrm{d} t} \mu_0 (Y_0^{-1}(x))\]

La fonction $f(x) = \frac{1}{v(Y_0^{-1}(x))} $ est négative elle est donc majorée par $0$ et minorée par $-1/\delta$ d'après la question 2.a..

\textbf{c.}
Pour définir le pseudo-inverse de Moore-Penrose, il faut que l'opérauteur $\Psi$ soit borné, ce point est bien vérifié pour toute solution $u$ du système (1) d'après la question 4.c..
L'image de $\Psi$ sont les fonctions $H^1[0,+\infty)$ à support sur $[0,Y_0^{-1}(L)]$.

\[ Im(\Psi) = \left\{\mu \in H^1[0,+\infty) \;|\; supp(\mu) \subset[0,Y_0^{-1}(L)] \right\} \]

On peut donc définir le pseudo inverse dont la valeur sur $Im(\Psi)$ vaut :

\begin{equation}
	 \Psi^\dagger \; : \; \left\vert
	\begin{array}{ccc}
	Im(\Psi) & \mapsto & \Y \\
	\mu_0 & \mapsto & \displaystyle \frac{1}{v(Y_0^{-1}(x))} \frac{\mathrm{d}}{\mathrm{d} t} \mu_0 (Y_0^{-1}(x)) \\
	\end{array} \right.
\end{equation}

et $D(\Psi^\dagger) = Im(\Psi) + Im(\Psi)^\perp$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Question 6. Résolution du problème inverse par la méthode de Tikhonov généralisée}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{a.}
Ce problème inverse revient à résoudre la question suivante : peut-on estimer $y=u^{in}$ la condition initiale par la mesure du moment d'ordre 0 d'une solution du système (1) ?
Comme dans le cadre du cours (chapitre 2) sur l'exemple du problème inverse de l'intégrale, ce problème est mal posé d'ordre 1 pour la norme sur $L^2$ sur $\mathscr{Z}$.

\textbf{b.}

On note à titre préliminaire :
\[
\begin{cases}
	\zea(t) = \Psi \yea(t) \\
	\zea'(t) = - Y_0'(t)\yea(Y_0(t))\\
	\zea(T) = \int_{Y_0(T)}^L \yea(x)dx = 0
\end{cases}
\]

Il vient ainsi :
\[
\begin{split}
	\int_0^T (Y_0'(t)\yea(Y_0(t)))(\Psi\yea - \alpha Y_0'(t)\yea(Y_0(t)))dt
	 & = \int_0^T (Y_0'(t)\yea(Y_0(t))) \Psi \yea(t)dt
	 - \int_0^T \alpha (Y_0'(t)\yea(Y_0(t)))^2 dt \\
	 &= - \int_0^T \zea'(t) \zea(t)dt
	 - \alpha \int_0^T \zea'(t)^2 dt\\
	 &= - \displaystyle \frac{1}{2}[\zea(t)^2]_0^T
	 - \alpha \int_0^T \zea'(t)^2 dt\\
	 & = \displaystyle \frac{1}{2}\zea(0)^2 
	 - \alpha \int_0^T \zea'(t)^2 dt
\end{split}
\]

D'autre part :

\[
\int_0^T (Y_0'(t)\yea(Y_0(t))) z_{\epsilon}(t)dt 
= - \int_0^T \zea'(t)z_{\epsilon}(t) dt
\]

Donc :
\[
\displaystyle \frac{1}{2}\zea(0)^2 
	 - \alpha \int_0^T \zea'(t)^2 dt
	 = - \int_0^T \zea'(t)z_{\epsilon}(t) dt
\]

De plus, pour obtenir l'inégalité, 
on cherche à exprimer $\zea'$ en fonction de $\yea$
Posons le changement de variable $s = Y_0(t)$,
et $ds = Y_0'(t)dt$ :

\[
\begin{split}
\int_0^T \zea'(t)^2 dt & = \int_0^T Y_0'(t)\yea(Y_0(t))^2 (Y_0'(t)dt) \\
                       & = \int_0^L Y_0'(Y_0^{-1}(s)) \, \yea(s)^2 ds\\
					   & \geq v_{min} \| \yea \|_{\Y}^2
\end{split}
\]

Puis, on cherche à exprimer $\zea(0)$ en fonction de $\yea$ :

\[
\begin{split}
	\zea(0)^2 &= (\int_0^L \yea(x)dx)^2 \\
	          & \leq (\int_0^L 1^2dx)(\int_0^L \yea(x)^2 dx) \\
			  & \leq L \| \yea \|_{\Y}^2
\end{split}
\]

Donc :
\[
\begin{split}
\| \yea \|_{\Y}^2 &= \int_0^L \yea(x)^2 dx \\
                  &\leq \displaystyle \frac{1}{v_{min}}
				      \int_0^T \zea'(t)^2 dt \\ 
				  &\leq \displaystyle \frac{1}{\alpha v_{min}}
				      (\displaystyle \frac{1}{2}\zea(0)^2 
				      + \int_0^T \zea'(t)z_{\epsilon}(t) dt)\\
					  &\leq \displaystyle \frac{1}{\alpha v_{min}}
					      (\displaystyle \frac{1}{2}\zea(0)^2 
					      + (\int_0^T \zea'(t)^2 dt)^{1/2}
						   (\int_0^Tz_{\epsilon}(t)^2 dt)\,)^{1/2})\\
				  &\leq \displaystyle \frac{1}{\alpha v_{min}}
				      (\frac{L}{2}  \| \yea \|_{\Y}^2
				      +  v_{max}^{1/2} \| \yea \|_{\Y}
					  \|z_{\epsilon} \|_{\Z})
\end{split}
\]

Soit, pour $0< 1-\displaystyle \frac{L}{2\alpha v_{min}} $  :

\[
\| \yea \|_{\Y}^2 (1-\displaystyle \frac{L}{2\alpha v_{min}})
  \leq \frac{v_{max}^{1/2}}{\alpha v_{min}}  \| \yea \|_{\Y} \|z_{\epsilon} \|_{\Z})
\]				  

Il vient donc :
\[
\| \yea \|_{\Y}  \leq f(\alpha) \|z_{\epsilon} \|_{\Z}
\]

Avec $f(\alpha) = \displaystyle \frac{2v_{max}^{1/2}}{2\alpha v_{min} -L}$

\vspace{0.3cm}
\textbf{c.}

Soit $y_{\alpha}$ solution de (7).

Alors comme $z\in H^1(0,T)$ et $y\in L^2(0,L)$, 
on a donc $\Psi y_{\alpha} \in H^1(0,T)$ par composition de l'intégrale d'une fonction de $L^2$
et le la fonction $Y_0$ de $C^2(0,T)$.

Donc $t \to Y_0'(t)y(Y_0(t))$ est également une fonction de $H^1(0,T)$
et on a presque partout :

\begin{equation}
	\label{8}
	 - Y_0'(t) y_{\alpha}(Y_0(t)) - \alpha(Y_0'(t) y_{\alpha}(Y_0(t)))' = z'(t)
\end{equation}

et $y_{\alpha}(L) = 0$.

Réciproquement, soit $y_{\alpha}$ solution de (8), 
on peut intégrer l'équation entre $t$ et $T$,
et sachant $y_\alpha (L) =0$ :

\[ 
\begin{split}
	\int_t^T [- Y_0'(s) y_{\alpha}(Y_0(s)) - \alpha (Y_0'(s) y_{\alpha}(Y_0(s)))' ] ds
	& = \int_t^T (\int_{Y_0(s)}^L y_{\alpha}(x)dx)'ds
	     - \alpha \int_t^T (Y_0'(s) y_{\alpha}(Y_0(s)))' ds \\
	& = \Psi y_{\alpha} (T) - \Psi y_{\alpha} (t)
	    - \alpha (Y_0'(T) y_{\alpha}(Y_0(T)))
		+ \alpha (Y_0'(t) y_{\alpha}(Y_0(t))) \\
    & = - \Psi y_{\alpha} (t) + \alpha (Y_0'(t) y_{\alpha}(Y_0(t)))
\end{split}
\]

Donc, avec $z(T)=0$, on obtient $y_\alpha$ est solution de :

\[ \Psi y_{\alpha} (t) - \alpha (Y_0'(t) y_{\alpha}(Y_0(t))) = z(t)\]

On pose alors $z_{\alpha}'(t) = - Y_0'(t)y_{\alpha}(Y_0(t))$,
et on observe que $z_{\alpha}'(T) =0$ et $z_{\alpha}(t) = - \int_{Y_0(t)}^L y_{\alpha}(x)dx$.

On remplace dans~\eqref{8}
$- Y_0'(t)y_{\alpha}(Y_0(t))$ par $z_{\alpha}'(t)$ :

\[ z_\alpha'(t) - \alpha (-z_\alpha'(t))' = z'(t) \]

On multiplie alors (8) par $z_{\alpha}'(t)$
et il vient :

\[ z_{\alpha}'(t)^2 + \alpha z_{\alpha}'(t) z_{\alpha}'' = z_{\alpha}'(t)z'(t) \]

On intègre entre $0$ et $T$ :

\[ \displaystyle  \int_0^T z_\alpha '(t)^2 dt - \alpha \frac{1}{2}z_\alpha '(0)^2
          =  \int_0^T z_\alpha '(t)z'(t)dt \]

Par le même raisonnement que la question précédente on calcule l'inégalité :

\[
\begin{split}
\| y_{\alpha} \|_{\mathscr{Y}}^2 &= \int_0^L y_\alpha(x)^2dx \\
	     & \leq \displaystyle \frac{1}{v_{min}} \int_0^T z'_{\alpha}(t)^2dt\\
	     &\leq \displaystyle \frac{1}{v_{min}}
				 ( \frac{\alpha}{2} z_\alpha '(0)^2 
				 	+ \int_0^T z_\alpha '(t)z'(t)dt) \\
		 & \leq \displaystyle \frac{1}{v_{min}}
			(\frac{\alpha}{2}  (-Y_0'(0)) y_\alpha (0)
			+ (\int_0^T z_\alpha'(t)^2 dt)^{1/2}
			 (\int_0^Tz'(t)^2 dt)\,)^{1/2} ) \\
		&\leq \displaystyle \frac{1}{v_{min}}
			(\| z_\alpha'\|_{\Y} \| z \|_{H^1} ) \\
		& \leq \displaystyle \frac{1}{v_{min}}
			( v_{max}^{1/2} \| y_\alpha \|_{\Y} \| z \|_{H^1} ) 
\end{split}
\]

Donc :

\[ \| y_{\alpha} \|_{\mathscr{Y}} \leq \displaystyle C_0
                                                     \| z \|_{H^1} \]

avec $C_0= \displaystyle \frac{ v_{max}^{1/2} }{ v_{min}}$.


\vspace{0.3cm}
\textbf{d.}

On soustrait à l'équation~\eqref{8} 
l'égalité $\Psi y = z$ :

\[
\Psi (y_\alpha - y) - \alpha Y_0'(t)(y_\alpha - y)(Y_0(t)) = \alpha Y_0'(t) y(Y_0(t))
\]

On dérive puisque $y \in H^1(0,L)$ on obtient pour presque tout $t$ :

 \[
 - Y_0'(t)(y_\alpha - y)(Y_0(t)) - \alpha (Y_0'(t)(y_\alpha - y)(Y_0(t)))' = \alpha (Y_0'(t) y(Y_0(t)))'
 \]
 
 On obtient l'équivalence entre les deux solutions en imposant $(y_\alpha - y)(L)=0$
 
 On multiplie par $z_1'(t) =  - Y_0'(t)(y_\alpha - y)(Y_0(t)) $ et il vient :
 
 \[
 z_1'(t)^2 + \alpha z_1'(t)z_1 ''(t) = \alpha z_1'(t)(Y_0'(t) y(Y_0(t)))'
 \]

Et par intégration :

\[
\int_0^T z_1'(t)^2dt - \alpha \displaystyle \frac{1}{2} z_1 '(0)^2 
  = \int_0^T \alpha z_1'(t)(Y_0'(t) y(Y_0(t)))' dt
\] 
Soit 

\[
\int_0^T z_1'(t)^2dt - \alpha \displaystyle \frac{1}{2} z_1 '(0)^2 
  = \int_0^T \alpha z_1'(t)(Y_0''(t) y(Y_0(t)) - Y_0'(t)^2 y'(Y_0(t))) dt
\] 

\[
\begin{split}
	\| y_\alpha - y \|_{\Y}^2 
	     & \leq \displaystyle \frac{1}{v_{min}} \int_0^T z_1'(t)^2 dt \\
		 & \leq \displaystyle \frac{1}{v_{min}}
		        ( \alpha \displaystyle \frac{1}{2} z_1 '(0)^2 
				+  \int_0^T \alpha z_1'(t)(w_{max}y(Y_0(t))
				- Y_0'(t)^2 y'(Y_0(t))) )  dt) \\
	   		 & \leq \displaystyle \frac{1}{v_{min}}
	   		        ( \alpha \displaystyle \frac{1}{2} z_1 '(0)^2 
	   				+ \alpha (\int_0^T  z_1'(t)^2 dt )^{1/2}
					(\int_0^T (w_{max}y(Y_0(t))
	   				- Y_0'(t)^2 y'(Y_0(t)))^2  dt)^{1/2} \\
  		 & \leq \displaystyle \frac{1}{v_{min}}
  		        ( \alpha \displaystyle \frac{1}{2} z_1 '(0)^2 
  				+ \alpha (\int_0^T  z_1'(t)^2 dt )^{1/2}
			(\int_0^T (w_{max}y(Y_0(t)))^2
  				+ (Y_0'(t)^2 y'(Y_0(t)))^2  dt)^{1/2} \\
		& \leq \displaystyle \frac{1}{v_{min}}
				( \frac{ L^2\alpha}{2} (-Y_0(0))(y_\alpha(0) - y(0))
			     + \alpha v_{max}^{1/2}\| y_\alpha - y \|_{\Y}
				  [w_{max} \|y\|_{Y} + v_{max}^2 \| y' \|_{\Y}]  ) \\
		& \leq \displaystyle \frac{1}{v_{min}}
		       ( \frac{ L^2\alpha}{2} v_{max} y(0)
			    + \alpha v_{max}^{1/2}\| y_\alpha - y \|_{\Y}^2
				[w_{max} + v_{max}^2] \|y\|_{H^1}   )
\end{split}
\]		 

Or,

\[ 0 \leq y(0) = -\int_0^L y'(x)dx \leq  L^{1/2} \| y \|_{H^1} \]

Donc :

\[ \| y_\alpha - y \|_{\Y} \leq (C_1 + C_2 \alpha) \| y \|_{H^1} \]

\textbf{e.}

Pour $0< 1-\displaystyle \frac{L}{2\alpha v_{min}} $ :

\[
\begin{split}
	\| \yea - y \|_{\Y} & \leq \| \yea - y_\alpha \|_{\Y} + \| y_\alpha - y \|_{\Y}\\ 	                                             & \leq f(\alpha) \| z_\epsilon \|_{\Z} 
	                          + \| y_\alpha \|_{\Y} + (C_1 + \alpha C_2) \| y \|_{H^1}\\
	                    & \leq f(\alpha) \| z_\epsilon \|_{\Z} + \| y_\alpha \|_{\Y} 
						      + (C_1 + \alpha C_2) \| y \|_{H^1}\\
	  	              & \leq f(\alpha) \| z_\epsilon - z \|_{\Z} 
					         + (C_0 +1) \| z \|_{H^1} 
	  						 + (C_1 + \alpha C_2) \| y \|_{H^1}
\end{split}
\]

Soit :

\[ \| \yea - y \|_{\Y} \leq f(\alpha) \epsilon + C_3 +C_4 \alpha \]

On note que cette inégalité est valable pour $\alpha > \displaystyle \frac{L}{2 v_{min}}$.
Une étude plus approffondie du comportement de $Y_0$ pourrait nous permettre de conclure sous quelle condition cette condition est effectivement vérifiée.
Dans ce cas, le choix optimal ext $\alpha^2 = 0(\epsilon)$.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Etude du problème inverse, second cas : $c(t)$ connu, on mesure $\mu_1$}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

				
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Question 7. Résolution du problème inverse par filtre de Kalman}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
\textbf{a.}

On définit la fonctionnelle moindre carrée à minimiser pour $c(t)$ connu, donc $v(t)$ connu :

\[ J_t(u^{in}) = \displaystyle frac{1}{2}      
              \alpha \| u^{in} \|_{\Y} +  
			  \displaystyle frac{1}{2}      
			  \gamma \int_0^t \| \mu_1(t) - \int_0^L x u(t,x)dx \|_{\Z} \]

Pour obtenir le problème aux deux bouts, on introduit le Lagrangien lié à la dynamique de l'équation de transport :

\[ L_t(u^{in},q) = J_t(u^{in}) + \langle \partial_t u(t,x) - (ac(t)-b) \partial_x u(t,x), q(t,x) \rangle_{\Y} \]

On note $A(t) = - (ac(t)-b) \partial_x $ et $A(t)^*$ son adjoint.
On introduit également les notations suivantes :
\begin{itemize}
	\item $C$ la fonction d'observation qui à $u(x,t) \to \int_0^L u(x,t)dx$ ;
	\item $C^*$ l'adjoint de $C$ pour la norme $\langle \;, \; \rangle_{\Z}$ ;
	\item $S(t)$ le semi groupe $C_0$ généré par $A(t)$.
\end{itemize}
Au point selle optimal $(\bar{u^in}, \bar{q})$ la dérivée de Fréchet en $u^{in}$ s'annule :

\[ \begin{split}
\partial_{u}L_t(u-u^{in},q) \cdot (\delta u) &= \partial_u J_t(u-u^{in}) \cdot (\delta u)  - \rangle A^*(t)q , \delta u \langle \\
                                      &= - \gamma \int_0^t \langle S(t)^*C^* (\mu_1(t) - CS(t)u ), \delta u \rangle_{\Z} 
										 + \langle - \partial_t q - A^*(t)q , \delta u \rangle_{\Y}
\end{split}\]

Soit la dynamique aux deux bouts pour les points optimaux $(\bar{u},\bar{q})$ :

\[
\begin{cases}
	\partial_t \bar{u} - A(t)\bar{u} =0 \\
	\partial_t \bar{q} + A(t)^* \bar{q} = - \gamma S(t)^*C^* (\mu_1(t) - CS(t)\bar{u} ) \\
	\bar{u}(0) = \bar{u}^{in}\\
	\bar{q}(t) = 0
\end{cases}
\]
	
\textbf{b.}

On définit l'estimateur de Kalman $\hat{u}(t)$ 
comme l'optimum $\bar{u}$ solution de l'équation précédente pour $t$ fixé
et le critère correspondant $J_t$.

On a alors $\hat{y}(t) = \displaystyle \frac{1}{\alpha} \bar{q}(0)$

\textbf{c.}

\[
\displaystyle \frac{\mathrm{d} \hat{y}_t }{\mathrm{d}s} = \frac{1}{\alpha} \frac{\mathrm{d}\bar{q}_t}{\mathrm{d}s} \bar{q} 
\]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Etude du problème inverse, second cas : $c(t)$ inconnu, on mesure $\mu_1$}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

				
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Question 8. 4D-Var}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\textbf{a.}

On définit la fonctionnelle moindre carrée à minimiser pour $c(t)$ connu, donc $v(t)$ connu :

\[ J_t(u^{in}) = \displaystyle frac{1}{2}      
              \alpha \| u^{in} \|_{\Y} +  
			  \displaystyle frac{1}{2}      
			  \gamma \int_0^t \| \mu_1(t) - \int_0^L x u(t,x)dx \|_{\Z} \]

Pour obtenir le problème aux deux bouts, on introduit le Lagrangien lié à la dynamique de l'équation de transport :

\[ L_t(u^{in},q) = J_t(u^{in}) + \langle \partial_t u(t,x) + A(u) u(t,x), q(t,x) \rangle_{\Y} \]

On introduit également les notations suivantes :
\begin{itemize}
    \item $A(u)$ la dynamique non linéaire et $A(u)^*$ son adjoint ;
	\item $C$ la fonction d'observation qui à $u(x,t) \to \int_0^L u(x,t)dx$ ;
	\item $C^*$ l'adjoint de $C$ pour la norme $\langle \;, \; \rangle_{\Z}$.
\end{itemize}
Au point selle optimal $(\bar{u^in}, \bar{q})$ la dérivée de Fréchet en $u^{in}$ s'annule :

\[ \begin{split}
\partial_{u}L_t(u-u^{in},q) \cdot (\delta u) &= \partial_u J_t(u-u^{in}) \cdot (\delta u)  - \rangle A^*(u)q , \delta u \langle \\
                                      &= - \gamma \int_0^t \langle C^*(u) (\mu_1(t) - C(u)u ), \delta u \rangle_{\Z} 
										 + \langle - \partial_t q - A^*(u)q , \delta u \rangle_{\Y}
\end{split}\]

Soit la dynamique aux deux bouts pour les points optimaux $(\bar{u},\bar{q})$ :

\[
\begin{cases}
	\partial_t \bar{u} - A(\bar{u})\bar{u} =0 \\
	\partial_t \bar{q} + A(\bar{u})^* \bar{q} = - \gamma C^*(u) (\mu_1(t) - C(\bar{u})\bar{u} ) \\
	\bar{u}(0) = \bar{u}^{in}\\
	\bar{q}(t) = 0
\end{cases}
\]

\textbf{b.}

Pour résoudre ce problème de façon pratique, on peut procéder à une descente de gradient :

\[
\begin{cases}
    u^{n+1} = u^n - \rho \nabla J_t (u^n) \\
	\nabla J_t(u^n) = \alpha u^n - \gamma \bar{q}_t(0)
\end{cases}
\]

Le paramètre de relaxation pourra être choisi comme le rapport des valeurs propres extrêmes de la hessienne.











	
\end{document}
