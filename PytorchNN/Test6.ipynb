{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal Operator - test\n",
    "\n",
    "We compute with tensor the proximal operator associated to hyperslab constraint\n",
    "in order to include it as an activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cdellava/Documents/phd/MyResNet\n",
      "/Users/cdellava/Documents/phd/PytorchNN\n",
      "/opt/anaconda3/envs/torchdeep/lib/python37.zip\n",
      "/opt/anaconda3/envs/torchdeep/lib/python3.7\n",
      "/opt/anaconda3/envs/torchdeep/lib/python3.7/lib-dynload\n",
      "\n",
      "/opt/anaconda3/envs/torchdeep/lib/python3.7/site-packages\n",
      "/opt/anaconda3/envs/torchdeep/lib/python3.7/site-packages/IPython/extensions\n",
      "/Users/cdellava/.ipython\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/cdellava/Documents/phd/MyResNet')\n",
    "\n",
    "for d in sys.path:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local\n",
    "# from IPsolver import cardan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cardan(torch.autograd.Function):  \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx,gamma_mu,xtilde,u,im_range,device=\"cpu\",mode_training=True):\n",
    "        \"\"\"\n",
    "\t    Finds the solution of the cubic equation involved in the computation of the proximity operator of the \n",
    "        logarithmic barrier of the hyperslab constraints (xmin< u^Tx <xmax) using the Cardano formula: x^3+ax^2+bx+c=0 \n",
    "        is rewritten as x^3+px+q=0. Selects the solution x such that x-a/3 is real and belongs to ]xmin,xmax[.\n",
    "        Parameters\n",
    "        ----------\n",
    "           gamma_mu (torch.FloatTensor): product of the barrier parameter and the stepsize, size n\n",
    "           xtilde (torch.FloatTensor): point at which the proximity operator is applied, size n\n",
    "           u_ker (torch.FloatTensor) : kernel conv u^T x_tilde, size n\n",
    "           im_range (list): minimal and maximal pixel values\n",
    "           device (string) : \n",
    "           mode_training (bool): indicates if the model is in training (True) or testing (False) (default is True)\n",
    "        Returns\n",
    "        -------\n",
    "           sol (torch.FloatTensor): proximity operator of gamma_mu*barrier at xtilde, size n \n",
    "        \"\"\"\n",
    "        # Device CPU/GPU\n",
    "        if device == \"cuda\":\n",
    "            dtype = torch.cuda.FloatTensor\n",
    "        else :\n",
    "            dtype = torch.FloatTensor\n",
    "        #initialize variables\n",
    "        size              = xtilde.size()\n",
    "        x1,x2,x3          = torch.zeros(1).type(dtype),torch.zeros(1).type(dtype),torch.zeros(1).type(dtype)   \n",
    "        crit,crit_compare = torch.zeros(1).type(dtype),torch.zeros(1).type(dtype)\n",
    "        sol               = torch.zeros(size).type(dtype),\n",
    "        xmin,xmax         = im_range\n",
    "        uTx               = torch.matmul(u,xtilde)\n",
    "        #set coefficients\n",
    "        a     = -(xmin+xmax+uTx)\n",
    "        b     = xmin*xmax + uTx*(xmin+xmax) - 2*gamma_mu*torch.norm(u)**2\n",
    "        c     = gamma_mu*(xmin+xmax) - uTx*xmin*xmax\n",
    "        p     = b - (a**2)/3\n",
    "        q     = c - a*b/3 + 2*(a**3)/27\n",
    "        delta = (p/3)**3 + (q/2)**2  \n",
    "        print(delta)\n",
    "\n",
    "        #three cases depending on the sign of delta\n",
    "        #########################################################################\n",
    "        #when delta is positive\n",
    "        if delta>0:\n",
    "            z1 = -q/2\n",
    "            z2 = torch.sqrt(delta)\n",
    "            u  = (z1+z2).sign() * torch.pow((z1+z2).abs(),1/3)\n",
    "            v  = (z1-z2).sign() * torch.pow((z1-z2).abs(),1/3) \n",
    "            x1 = u+v   \n",
    "            x2 = -(u + v)/2 ; #real part of the complex solution\n",
    "            x3 = -(u + v)/2 ; #real part of the complex solution\n",
    "        #########################################################################\n",
    "        #when delta is 0\n",
    "        elif delta==0:\n",
    "            x1 = 3 *q / p \n",
    "            x2 = -1.5 * q / p\n",
    "            x3 = -1.5 * q / p \n",
    "        #########################################################################\n",
    "        #when delta is negative\n",
    "        elif delta<0:\n",
    "            cos = (-q/2) * ((27 / torch.pow(p,3)).abs()).sqrt() \n",
    "            cos[cos<-1] = 0*cos[cos<-1]-1\n",
    "            cos[cos>1]  = 0*cos[cos>1]+1\n",
    "            phi         = torch.acos(cos)\n",
    "            tau         = 2 * ((p/3).abs()).sqrt() \n",
    "            x1     = tau * torch.cos(phi/3) \n",
    "            x2     = -tau * torch.cos((phi + np.pi)/3)\n",
    "            x3     = -tau * torch.cos((phi - np.pi)/3)\n",
    "        #########################################################################\n",
    "        x1   = x1-a/3\n",
    "        x2   = x2-a/3\n",
    "        x3   = x3-a/3\n",
    "        print(x3)\n",
    "        # when gamma_mu is very small there might be some numerical instabilities\n",
    "        # in case there are nan values, we set the corresponding pixels equal to 2*xmax\n",
    "        # these values will be replaced by valid values at least once\n",
    "        if (x1!=x1).any():\n",
    "            x1[x1!=x1]=2*xmax\n",
    "        if (x2!=x2).any():\n",
    "            x2[x2!=x2]=2*xmax\n",
    "        if (x3!=x3).any():\n",
    "            x3[x3!=x3]=2*xmax\n",
    "        sol  = xtilde + (x1 - uTx)/torch.norm(u)**2*u\n",
    "        #########################################################################\n",
    "        #take x1\n",
    "        p1 = sol\n",
    "        uTp1 = torch.matmul(u,p1)\n",
    "        if (uTp1>xmin)&(uTp1<xmax):\n",
    "            crit[0] = -(torch.log(uTp1-xmin)+torch.log(xmax-uTp1))\n",
    "            crit = 0.5*torch.norm(p1-xtilde)**2+gamma_mu*crit\n",
    "        else:\n",
    "            crit[0] = np.inf\n",
    "        #########################################################################\n",
    "        #test x2\n",
    "        p2 = xtilde + (x2 - uTx)/torch.norm(u)**2*u\n",
    "        uTp2 = torch.matmul(u,p2)\n",
    "        if (uTp2 >xmin)&(uTp2 <xmax): \n",
    "            crit_compare[0]  = -(torch.log(uTp2-xmin)+torch.log(xmax-uTp2))\n",
    "            crit_compare  = 0.5*torch.norm(p2-xtilde)**2+gamma_mu*crit_compare\n",
    "        else:\n",
    "            crit_compare[0] = np.inf\n",
    "        if crit_compare<=crit:\n",
    "            print(p2)\n",
    "            sol  = p2\n",
    "            crit = crit_compare\n",
    "        #########################################################################\n",
    "        #test x3\n",
    "        p3 = xtilde + (x3 - uTx)/torch.norm(u)**2*u\n",
    "        uTp3 = torch.matmul(u,p3)\n",
    "        if (uTp3>xmin)&(uTp3<xmax):\n",
    "            crit_compare[0] = -(torch.log(uTp3-xmin)+torch.log(xmax-uTp3))\n",
    "            crit_compare = 0.5*torch.norm(p3-xtilde)**2+gamma_mu*crit_compare\n",
    "        else:\n",
    "            crit_compare[0] = np.inf\n",
    "        if crit_compare<=crit:\n",
    "            print(p3)\n",
    "            sol  = p3\n",
    "            crit = crit_compare\n",
    "        #########################################################################\n",
    "        # when gamma_mu is very small and xtilde is very close to one of the bounds,\n",
    "        # the solution of the cubic equation is not very well estimated -> test xtilde\n",
    "        # denom = (sol-xmin)*(sol-xmax)-2*gamma_mu -(sol-xtilde)*(xmin+xmax-2*sol)\n",
    "        if (uTx>xmin)&(uTx<xmax):\n",
    "            crit_compare = -(torch.log(xmax-uTx)+torch.log(uTx-xmin))\n",
    "            crit_compare = gamma_mu*crit_compare\n",
    "        else:\n",
    "            crit_compare[0] = np.inf\n",
    "        if crit_compare<crit :\n",
    "            sol = xtilde\n",
    "        \n",
    "        if mode_training==True:\n",
    "            ctx.save_for_backward(gamma_mu,xtilde,sol)\n",
    "        return sol\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output_var):\n",
    "        \"\"\"\n",
    "        Computes the first derivatives of the proximity operator of the log barrier with respect to x and gamma_mu.\n",
    "            This method is automatically called by the backward method of the loss function.\n",
    "        Parameters\n",
    "        ----------\n",
    "           ctx (list): list of torch.FloatTensors, variable saved during the forward operation\n",
    "           grad_output_var (torch.FloatTensor): gradient of the loss wrt the output of cardan\n",
    "        Returns\n",
    "        -------\n",
    "           grad_input_gamma_mu (torch.FloatTensor): gradient of the prox wrt gamma_m \n",
    "           grad_input_u (torch.FloatTensor): gradient of the prox wrt x\n",
    "           None: no gradient wrt the image range\n",
    "           None: no gradient wrt the mode\n",
    "        \"\"\"\n",
    "        xmin           = 0\n",
    "        xmax           = 1\n",
    "        dtype          = torch.cuda.FloatTensor\n",
    "        grad_output    = grad_output_var.data\n",
    "        gamma_mu,u,x   = ctx.saved_tensors\n",
    "        denom          = (x-xmin)*(x-xmax)-2*gamma_mu -(x-u)*(xmin+xmax-2*x)\n",
    "        \n",
    "        idx                 = denom.abs()>1e-7\n",
    "        denom[1-idx]        = denom[1-idx]+1\n",
    "        grad_input_gamma_mu = (2*x-(xmin+xmax))/denom\n",
    "        grad_input_u        = ((x**2-x*(xmin+xmax)+xmin*xmax))/denom\n",
    "        # if denom is very small, it means that gamma_mu is very small and u is very close to one of the bounds,\n",
    "        # there is a discontinuity when gamma_mu tends to zero, if 0<u<1 the derivative wrt x is approximately equal to \n",
    "        # 1 and the derivative wrt gamma_mu is approximated by 10^5 times the sign of 2*x[1-idx]-(xmin+xmax)\n",
    "        grad_input_gamma_mu[1-idx] = 0*grad_input_gamma_mu[1-idx]+1e5*torch.sign(2*x[1-idx]-(xmin+xmax))\n",
    "        grad_input_u[1-idx]        = 0*grad_input_u[1-idx]+1\n",
    "        \n",
    "        grad_input_gamma_mu = (grad_input_gamma_mu*grad_output).sum(1).sum(1).sum(1).unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "        grad_input_u        = grad_input_u*grad_output\n",
    "        \n",
    "        # safety check for numerical instabilities\n",
    "        if (grad_input_gamma_mu!=grad_input_gamma_mu).any():\n",
    "            print('there is a nan in grad_input_gamma_mu')\n",
    "            if (x!=x).any():\n",
    "                print('there is a nan in x')\n",
    "            sys.exit()\n",
    "        if (grad_input_u!=grad_input_u).any():\n",
    "            print('there is a nan in grad_input_u')\n",
    "            sys.exit()\n",
    "        \n",
    "        grad_input_gamma_mu = Variable(grad_input_gamma_mu.type(dtype),requires_grad=True)\n",
    "        grad_input_u        = Variable(grad_input_u.type(dtype),requires_grad=True)\n",
    "        \n",
    "        return grad_input_gamma_mu, grad_input_u, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2110)\n",
      "tensor(-7.6538e-05)\n",
      "tensor(-0.2017)\n",
      "tensor([1.0000e-02, 4.9011e+00, 9.6021e+00, 3.1703e+01, 2.0604e+01, 1.4505e+01,\n",
      "        1.9406e+01])\n",
      "tensor([ 1.0000e-02, -7.2093e-01, -1.6419e+00,  1.4837e+01, -1.8837e+00,\n",
      "        -1.3605e+01, -1.4326e+01])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-02, 2.0000e+00, 3.8000e+00, 2.3000e+01, 9.0000e+00, 0.0000e+00,\n",
       "        2.0000e+00])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tilde = torch.FloatTensor([0.01,2,3.8,23,9,0,2])\n",
    "u = torch.FloatTensor(0.01*np.linspace(0,1,7))\n",
    "print(torch.matmul(u,x_tilde))\n",
    "im_range = [0,1]\n",
    "gamma = 1\n",
    "mu = 0.1\n",
    "\n",
    "cardan.apply(gamma*mu,x_tilde,u,im_range,\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
