{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle non linéaire - Accelerated Sinkhorn RNA\n",
    "\n",
    "Ici on reprend tout ce qu'on a fait, mais on change la loss.\n",
    "On utilise la distance de Wasserstein (transport optimal), calculé par un algorithme de Sinkorhn. \n",
    "On veut transpoter une distribution a en b.\n",
    "\n",
    "We consider (for stabilization purpose)\n",
    "the variables $f = \\epsilon \\log(u/a)$ and $g = \\epsilon \\log(v/b)$.\n",
    "In these variables, Sinkhorn algorithm can be interpreted as an alternate maximization algorithm, to solve the following \"dual\" problem:\n",
    "$$\n",
    "\\max_{f\\in R^n, g \\in R^m} F(f,g) =  \\sum_{i=1}^n f_i a_i + \\sum_{j=1}^m g_j b_j - \\epsilon \\sum_{i,j} a_ib_j \\exp \\left( (f_i + g_j -C_{ij})/\\epsilon \\right).\n",
    "$$\n",
    "\n",
    "In these variables, the algorithm is initialized with $g = 0_m$ and the updates read\n",
    "$$\n",
    "f_i \\longleftarrow - \\epsilon \\log \\sum_{j} b_j \\exp ((g_j - C_{ij})/\\epsilon),\\, \\forall i \\\\\n",
    "g_j \\longleftarrow - \\epsilon \\log \\sum_{i} a_i \\exp ((f_i - C_{ij})/\\epsilon),\\, \\forall j\n",
    "$$\n",
    "\n",
    "The optimal transport plan $P=(P_{ij})_{\\substack{i=1\\dots n\\\\j=1\\dots m}}$ can be recovered as \n",
    "$$\n",
    "P_{ij} = a_ib_j\\exp\\left( (f_i+g_j - C_{ij})/\\epsilon \\right).\n",
    "$$\n",
    "\n",
    "On voit tout de suite une difficulté :\n",
    "\n",
    "- The Gibbs kernel K is a Gaussian convolution,\n",
    "$$ \n",
    "\\begin{cases}\n",
    "C_{i,j} = i/N-j/N)^2 , \\\\\n",
    " K_{i,j} = e^{ -(i/N-j/N)^2/\\epsilon }, \n",
    "\\end{cases}\n",
    " $$\n",
    "et est indépendant de a et b\n",
    "\n",
    "- Le coût final est \n",
    "$$ W = \\langle P,C \\rangle $$ \n",
    "la loss sera donc calculée à partir des dérivées des plan de transport u et v.\n",
    "En effet\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial W}{\\partial a} = & \\frac{\\partial \\langle P,C \\rangle}{\\partial a} \\\\ \n",
    "                = &  \\langle\\frac{\\partial \\text{exp} (-C_{ij} + u_i + v_j) / \\epsilon) }{\\partial a}, C \\rangle \\\\\n",
    "                = &  \\langle\\frac{\\partial \\text{exp} (u_i) / \\epsilon) }{\\partial a}, C \\rangle \n",
    "                 + \\langle\\frac{\\partial \\text{exp} (v_j) / \\epsilon) }{\\partial a}, C \\rangle \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "Et donc à travers toutes les itérations... d'où le besoin d'accélérer l'algo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical data\n",
    "l = 1\n",
    "tau = 1\n",
    "dep = 1\n",
    "# Numerical data\n",
    "nx = 200\n",
    "dx = l/(nx+1)\n",
    "nt = 200\n",
    "dt = tau/nt\n",
    "T_operator = 1/100*dx*np.tri(nt, nx, 0, dtype=int)\n",
    "# Data sample\n",
    "nsamp = 400\n",
    "x_dagger = np.zeros((nsamp,nx))\n",
    "y = np.zeros((nsamp,nt))\n",
    "x_grid = np.linspace(0,l,nx)\n",
    "#\n",
    "x_sample = np.zeros((nsamp,nx))\n",
    "#\n",
    "for i in range(0,nsamp):\n",
    "    mu = l/2\n",
    "    sigma = 10*l\n",
    "    x_dagger[i] = (sigma*np.sqrt(2*np.pi))**-1*np.exp(-(x_grid-mu)**2/2*sigma**2)\n",
    "    x_dagger[i] = x_dagger[i]/x_dagger[i].sum()\n",
    "    y[i] = T_operator.dot(x_dagger[i]) \n",
    "    xi = np.random.uniform(-0.005,0.005,nt)\n",
    "    y[i] += xi*np.linalg.norm(y[i])/np.linalg.norm(xi)\n",
    "    x_sample[i] = np.transpose(T_operator).dot(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularisation operator\n",
    "D_operator = np.diag(np.ones(nx-1),1)+ np.diag(np.ones(nx-1),-1)-2*np.eye(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.from_numpy(x_sample)\n",
    "y_tensor = torch.from_numpy(x_dagger)\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [300, 100])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-99924f3df9fa>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-99924f3df9fa>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    for k in range(number_of_layers)]\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, number_of_layers, T, D, nx):\n",
    "        super().__init__()\n",
    "        self.alpha = [nn.Parameter(torch.empty(1, dtype=torch.float,\\\n",
    "                                               requires_grad=True).fill_(1.0))\\\n",
    "                      for k in range(number_of_layers)]\n",
    "#         self.linear_output_transformation = nn.Linear(weight_dimensions, number_of_classes,\\\n",
    "#                                                       bias=False)\n",
    "        self.activation_function = nn.Tanh()  \n",
    "        self.activation_function_ter = nn.ReLU() \n",
    "        self.number_of_layers = number_of_layers\n",
    "        # Physical model\n",
    "        self.T = torch.from_numpy(np.transpose(T).dot(T))\n",
    "        self.D = torch.from_numpy(np.transpose(D).dot(D))\n",
    "        self.nx = nx\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = torch.transpose(x,0,-1)\n",
    "        for k in range(self.number_of_layers):\n",
    "            tensor_grad = torch.eye(nx)\\\n",
    "              - self.T \\\n",
    "              - self.alpha[k]*self.D\n",
    "            y = torch.matmul(tensor_grad,y)\n",
    "            y = self.activation_function(y)\n",
    "        y = self.activation_function_ter(y)\n",
    "        y = y/torch.sum(y)\n",
    "        return torch.transpose(y,0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(10,T_operator,D_operator,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11f01c350>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model(train_dataset[0][0])\n",
    "y_test = train_dataset[0][1]\n",
    "plt.plot(y_pred.detach().numpy(),label=\"a\")\n",
    "plt.plot(y_test,label=\"b\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_loss(a, b, epsilon, n, niter):\n",
    "    \"\"\"\n",
    "    Given two emprical measures defined on a uniform grid xi = yi = i/n \n",
    "    (they are thue often refered to as \"histograms\"),\n",
    "    outputs an approximation of the OT cost with regularization parameter epsilon\n",
    "    niter is the max. number of steps in sinkhorn loop\n",
    "    \"\"\"\n",
    "\n",
    "    # Definition of the cost matrix :\n",
    "    t = np.linspace(0,1,n)\n",
    "    [Y,X] = np.meshgrid(t,t)\n",
    "    C_np = (X-Y)**2\n",
    "    C = Variable(torch.from_numpy(C_np), requires_grad=False)\n",
    "\n",
    "    # Parameters of the Sinkhorn algorithm.\n",
    "    tau = -.8  # nesterov-like acceleration\n",
    "    thresh = 10**(-1)  # stopping criterion\n",
    "\n",
    "    # Elementary operations \n",
    "    # .....................................................................\n",
    "    def ave(u, u1):\n",
    "        \"Over-relaxation to accelerate the convergence of the fixed-point algorithm.\" \n",
    "        \"It consists in replacing the update by a linear combination of the new and previous iterate. \"\n",
    "        return tau * u + (1 - tau) * u1\n",
    "\n",
    "    def M(u, v):\n",
    "        \"Modified cost for logarithmic updates\"\n",
    "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
    "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / epsilon\n",
    "\n",
    "    def lse(A):\n",
    "        \"log-sum-exp\"\n",
    "        return torch.log(torch.exp(A).sum(1, keepdim=True) + 1e-6)  # add 10^-6 to prevent NaN\n",
    "\n",
    "    # Actual Sinkhorn loop \n",
    "    # ......................................................................\n",
    "    f = torch.zeros_like(a)\n",
    "    g = torch.zeros_like(a)\n",
    "    actual_nits = 0 \n",
    "    err = 0.\n",
    "\n",
    "    for i in range(niter):\n",
    "        f1 = f  # used to check the update error\n",
    "        # Stable update u <- eps ( log a_i - log sum exp (-c_{ij} + f_i + g_j)/eps + f_i\n",
    "        f = epsilon * (torch.log(a + 1e-6) - lse(M(f, g)).squeeze()) + f \n",
    "        # Stable update g <- eps ( log b_j - log sum exp (-c_{ij} + f_i + g_j)/eps + g_j\n",
    "        g = epsilon * (torch.log(b + 1e-6) - lse(M(f,g).transpose(-2, -1)).squeeze()) + g\n",
    "        # Error check\n",
    "        err = (f - f1).abs().sum()\n",
    "        actual_nits += 1\n",
    "        if (err < thresh).data.numpy():\n",
    "            break\n",
    "            \n",
    "    \n",
    "    # Cost computatiom\n",
    "    # ......................................................................\n",
    "    F, G = f, g\n",
    "    # Transport plan P_{ij} = a_i b_j exp (- C_{ij}+f_i+g_j )/\\epsilon\n",
    "    P = torch.exp(torch.log(a.unsqueeze(-1))+ torch.log(b.unsqueeze(-2)) + M(F, G))  \n",
    "    # Sinkhorn cost\n",
    "    cost = torch.sum(P * C)  \n",
    "\n",
    "    return cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_loss(_Loss):\n",
    "    def __init__(self): \n",
    "        super(My_loss, self).__init__()\n",
    "        self.epsilon = 0.1\n",
    "        self.n = 200\n",
    "        self.niter = 10\n",
    " \n",
    "    def forward(self, output, target):\n",
    "        computed_loss = sinkhorn_loss(output, target, self.epsilon, self.n, self.niter)\n",
    "        return computed_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = My_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(train_dataset[0][0])\n",
    "y_test = train_dataset[12][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD(model.alpha, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def train_step(x, y):\n",
    "        # Sets model to TRAIN mode\n",
    "        model.train()\n",
    "        # Makes predictions\n",
    "        y_pred = model(x)\n",
    "        print(y_pred)\n",
    "        # Computes loss\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "        # Updates parameters and zeroes gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    # Returns the function that will be called inside the train loop\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the train_step function for our model, \n",
    "# loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0140, 0.0000,  ..., 0.0009, 0.0000, 0.0006],\n",
      "        [0.0000, 0.0176, 0.0000,  ..., 0.0006, 0.0000, 0.0003],\n",
      "        [0.0000, 0.0184, 0.0000,  ..., 0.0005, 0.0000, 0.0002],\n",
      "        ...,\n",
      "        [0.0000, 0.0141, 0.0000,  ..., 0.0000, 0.0005, 0.0000],\n",
      "        [0.0000, 0.0121, 0.0000,  ..., 0.0000, 0.0004, 0.0000],\n",
      "        [0.0000, 0.0140, 0.0000,  ..., 0.0000, 0.0010, 0.0000]],\n",
      "       dtype=torch.float64, grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "0  %%%% loss =  nan\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "1  %%%% loss =  nan\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "2  %%%% loss =  nan\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "3  %%%% loss =  nan\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "4  %%%% loss =  nan\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "5  %%%% loss =  nan\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "6  %%%% loss =  nan\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "7  %%%% loss =  nan\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "8  %%%% loss =  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64,\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "9  %%%% loss =  nan\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "n_epochs = 10\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "i=0\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "    print(i,\" %%%% loss = \",loss)\n",
    "    i+=1\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            \n",
    "            model.eval()\n",
    "\n",
    "            yhat = model(x_val)\n",
    "            val_loss = loss_fn(y_val, yhat)\n",
    "            val_losses.append(val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11efbcf10>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANoklEQVR4nO3dUYic13mH8edvqWoodZxSbSBIitehMkSYgs1iXAKNg90i60K6cYMEJk0RFknr9CKh4OLiBuWqDq0hoDYRrXETiB0lF8kSFARNbVxM5GqNHceSUdkqTrTI1JvE9Y1xbNG3FzMJw2p251tpdkd79PxAMN98RzPv0a4ej2d2NKkqJEkb33WTHkCSNB4GXZIaYdAlqREGXZIaYdAlqRGbJ3XHW7durenp6UndvSRtSM8///zPqmpq2LmJBX16epq5ublJ3b0kbUhJfrLcOZ9ykaRGGHRJaoRBl6RGGHRJaoRBl6RGjAx6kseSvJ7k5WXOJ8mXkswneSnJbeMfU5I0SpdH6I8Du1c4fw+ws//rEPBPVz6WJGm1Rga9qp4BfrHCkn3AV6vnJPC+JB8Y14CSpG7G8Rz6NuD8wPFC/7pLJDmUZC7J3OLi4hjuWpL0K+MIeoZcN/RTM6rqaFXNVNXM1NTQd65Kki7TOIK+AOwYON4OXBjD7UqSVmEcQZ8FPtH/aZc7gDer6rUx3K4kaRVG/uNcSZ4A7gS2JlkA/hb4DYCq+jJwHNgDzANvAX+2VsNKkpY3MuhVdWDE+QL+YmwTSZIui+8UlaRGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGdAp6kt1JziaZT/LgkPMfTPJUkheSvJRkz/hHlSStZGTQk2wCjgD3ALuAA0l2LVn2N8CxqroV2A/847gHlSStrMsj9NuB+ao6V1XvAE8C+5asKeC9/cs3ABfGN6IkqYsuQd8GnB84XuhfN+jzwH1JFoDjwGeG3VCSQ0nmkswtLi5exriSpOV0CXqGXFdLjg8Aj1fVdmAP8LUkl9x2VR2tqpmqmpmamlr9tJKkZXUJ+gKwY+B4O5c+pXIQOAZQVT8A3gNsHceAkqRuugT9FLAzyU1JttB70XN2yZqfAncBJPkwvaD7nIokraORQa+qi8ADwAngFXo/zXI6yeEke/vLPgfcn+SHwBPAJ6tq6dMykqQ1tLnLoqo6Tu/FzsHrHh64fAb4yHhHkySthu8UlaRGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJakSnoCfZneRskvkkDy6z5uNJziQ5neTr4x1TkjTK5lELkmwCjgB/BCwAp5LMVtWZgTU7gb8GPlJVbyR5/1oNLEkarssj9NuB+ao6V1XvAE8C+5asuR84UlVvAFTV6+MdU5I0SpegbwPODxwv9K8bdDNwc5Jnk5xMsnvYDSU5lGQuydzi4uLlTSxJGqpL0DPkulpyvBnYCdwJHAD+Ocn7LvlNVUeraqaqZqamplY7qyRpBV2CvgDsGDjeDlwYsuY7VfVuVf0YOEsv8JKkddIl6KeAnUluSrIF2A/MLlnzbeBjAEm20nsK5tw4B5UkrWxk0KvqIvAAcAJ4BThWVaeTHE6yt7/sBPDzJGeAp4C/qqqfr9XQkqRLpWrp0+HrY2Zmpubm5iZy35K0USV5vqpmhp3znaKS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1IhOQU+yO8nZJPNJHlxh3b1JKsnM+EaUJHUxMuhJNgFHgHuAXcCBJLuGrLse+EvguXEPKUkarcsj9NuB+ao6V1XvAE8C+4as+wLwCPD2GOeTJHXUJejbgPMDxwv9634tya3Ajqr67ko3lORQkrkkc4uLi6seVpK0vC5Bz5Dr6tcnk+uAR4HPjbqhqjpaVTNVNTM1NdV9SknSSF2CvgDsGDjeDlwYOL4euAV4OsmrwB3ArC+MStL66hL0U8DOJDcl2QLsB2Z/dbKq3qyqrVU1XVXTwElgb1XNrcnEkqShRga9qi4CDwAngFeAY1V1OsnhJHvXekBJUjebuyyqquPA8SXXPbzM2juvfCxJ0mr5TlFJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGdAp6kt1JziaZT/LgkPOfTXImyUtJvp/kxvGPKklaycigJ9kEHAHuAXYBB5LsWrLsBWCmqn4f+BbwyLgHlSStrMsj9NuB+ao6V1XvAE8C+wYXVNVTVfVW//AksH28Y0qSRukS9G3A+YHjhf51yzkIfG/YiSSHkswlmVtcXOw+pSRppC5Bz5DraujC5D5gBvjisPNVdbSqZqpqZmpqqvuUkqSRNndYswDsGDjeDlxYuijJ3cBDwEer6pfjGU+S1FWXR+ingJ1JbkqyBdgPzA4uSHIr8BVgb1W9Pv4xJUmjjAx6VV0EHgBOAK8Ax6rqdJLDSfb2l30R+G3gm0leTDK7zM1JktZIl6dcqKrjwPEl1z08cPnuMc8lSVol3ykqSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY3oFPQku5OcTTKf5MEh538zyTf6559LMj3uQSVJKxsZ9CSbgCPAPcAu4ECSXUuWHQTeqKrfAx4F/m7cg0qSVtblEfrtwHxVnauqd4AngX1L1uwD/rV/+VvAXUkyvjElSaN0Cfo24PzA8UL/uqFrquoi8Cbwu0tvKMmhJHNJ5hYXFy9vYknSUF2CPuyRdl3GGqrqaFXNVNXM1NRUl/kkSR11CfoCsGPgeDtwYbk1STYDNwC/GMeAkqRuugT9FLAzyU1JtgD7gdkla2aBP+1fvhf496q65BG6JGntbB61oKouJnkAOAFsAh6rqtNJDgNzVTUL/AvwtSTz9B6Z71/LoSVJlxoZdICqOg4cX3LdwwOX3wb+ZLyjSZJWw3eKSlIjDLokNcKgS1IjDLokNSKT+unCJIvATy7zt28FfjbGcTYC93xtcM/XhivZ841VNfSdmRML+pVIMldVM5OeYz2552uDe742rNWefcpFkhph0CWpERs16EcnPcAEuOdrg3u+NqzJnjfkc+iSpEtt1EfokqQlDLokNeKqDvq1+OHUHfb82SRnkryU5PtJbpzEnOM0as8D6+5NUkk2/I+4ddlzko/3v9ank3x9vWcctw7f2x9M8lSSF/rf33smMee4JHksyetJXl7mfJJ8qf/n8VKS2674TqvqqvxF75/q/W/gQ8AW4IfAriVr/hz4cv/yfuAbk557Hfb8MeC3+pc/fS3sub/ueuAZ4CQwM+m51+HrvBN4Afid/vH7Jz33Ouz5KPDp/uVdwKuTnvsK9/yHwG3Ay8uc3wN8j94nvt0BPHel93k1P0K/Fj+ceuSeq+qpqnqrf3iS3idIbWRdvs4AXwAeAd5ez+HWSJc93w8cqao3AKrq9XWecdy67LmA9/Yv38Cln4y2oVTVM6z8yW37gK9Wz0ngfUk+cCX3eTUHfWwfTr2BdNnzoIP0/gu/kY3cc5JbgR1V9d31HGwNdfk63wzcnOTZJCeT7F636dZGlz1/HrgvyQK9z1/4zPqMNjGr/fs+UqcPuJiQsX049QbSeT9J7gNmgI+u6URrb8U9J7kOeBT45HoNtA66fJ0303va5U56/xf2H0luqar/XePZ1kqXPR8AHq+qv0/yB/Q+Be2Wqvq/tR9vIsber6v5Efq1+OHUXfZMkruBh4C9VfXLdZptrYza8/XALcDTSV6l91zj7AZ/YbTr9/Z3qurdqvoxcJZe4DeqLns+CBwDqKofAO+h949YtarT3/fVuJqDfi1+OPXIPfeffvgKvZhv9OdVYcSeq+rNqtpaVdNVNU3vdYO9VTU3mXHHosv39rfpvQBOkq30noI5t65TjleXPf8UuAsgyYfpBX1xXadcX7PAJ/o/7XIH8GZVvXZFtzjpV4JHvEq8B/gveq+OP9S/7jC9v9DQ+4J/E5gH/hP40KRnXoc9/xvwP8CL/V+zk555rfe8ZO3TbPCfcun4dQ7wD8AZ4EfA/knPvA573gU8S+8nYF4E/njSM1/hfp8AXgPepfdo/CDwKeBTA1/jI/0/jx+N4/vat/5LUiOu5qdcJEmrYNAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIa8f+HT9K8XY8HjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
