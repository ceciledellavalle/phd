{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "C'est parti maintenant pour l'entrainement sur les données pre-traitees et avec l'algo dans l'espace des vecteurs propres, derniere etape avant le calcul de la constante de Lipschitz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "# local\n",
    "from MyResNet.pretreat import LoadDataSet, CreateDataSet\n",
    "from MyResNet.myfunc import Physics\n",
    "from MyResNet.myfunc import MyMatmul\n",
    "from MyResNet.model import MyModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramètres physiques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a   = 1\n",
    "p   = 1\n",
    "nx  = 2000\n",
    "m   = 20\n",
    "sim = Physics(nx,m,a,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charge les donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 1, 20])\n"
     ]
    }
   ],
   "source": [
    "folder  = './MyResNet/Datasets'\n",
    "nsample = 50\n",
    "train_set, val_set = CreateDataSet(sim,folder,noise=0.0,nsample=nsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On definit le modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = MyModel(sim,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On definit la loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_set,val_set,nb_epochs):\n",
    "    \"\"\"\n",
    "    Trains iRestNet.\n",
    "    \"\"\"      \n",
    "    # to store results\n",
    "    loss_train   =  np.zeros(nb_epochs)\n",
    "    loss_val     =  np.zeros(nb_epochs)\n",
    "    loss_min_val =  float('Inf')\n",
    "    # defines the optimizer\n",
    "    lr_i        = 0.01\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()),lr=lr_i)\n",
    "\n",
    "    #==========================================================================================================\n",
    "    # trains for several epochs\n",
    "    for epoch in range(0,nb_epochs): \n",
    "        # sets training mode\n",
    "        model.train()\n",
    "        # modifies learning rate\n",
    "        if epoch>0:\n",
    "            lr_i      = lr_i*0.9 \n",
    "            optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()), lr=lr_i)\n",
    "        # TRAINING\n",
    "        # goes through all minibatches\n",
    "        for i,minibatch in enumerate(train_set):\n",
    "            [y, x] = minibatch    # get the minibatch\n",
    "            x_init    = Variable(y,requires_grad=False)\n",
    "            x_true    = Variable(x,requires_grad=False)\n",
    "            x_pred    = model(x_init,x_init) \n",
    "                    \n",
    "            # Computes and prints loss\n",
    "            loss                = loss_fn(x_pred, x_true)\n",
    "            loss_train[epoch] += torch.Tensor.item(loss)\n",
    "                    \n",
    "            # sets the gradients to zero, performs a backward pass, and updates the weights.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # normalisation\n",
    "        loss_train[epoch] = loss_train[epoch]/i\n",
    "        #\n",
    "        #\n",
    "        # VALIDATION AND STATS\n",
    "        if epoch%1==0:\n",
    "            with torch.no_grad():\n",
    "            # saves signal and model state  \n",
    "            # utils.save_image(x_pred.data,os.path.join(\n",
    "            #            folder,'training',str(epoch)+'_restored_images.png'),normalize=True)\n",
    "            # torch.save(self.last_layer.state_dict(),os.path.join(folder,'trained_post-processing.pt'))\n",
    "            # torch.save(self.model.state_dict(),os.path.join(folder,'trained_model.pt'))\n",
    "\n",
    "            # tests on validation set\n",
    "                model.eval()      # evaluation mode\n",
    "                for i,minibatch in enumerate(val_set):\n",
    "                    [y, x] = minibatch            # gets the minibatch\n",
    "                    x_true    = Variable(x,requires_grad=False)\n",
    "                    x_init    = Variable(y,requires_grad=False)\n",
    "                    x_pred = model(x_init,x_init).detach()\n",
    "                    \n",
    "                    # computes loss on validation set\n",
    "                    loss_val[epoch] += torch.Tensor.item(loss_fn(x_pred, x_true))\n",
    "                # normalisation\n",
    "                loss_val[epoch] = loss_val[epoch]/i\n",
    "            # print stat\n",
    "            print(\"epoch : \", epoch,\" ----- \",\"validation : \",loss_val[epoch])\n",
    "\n",
    "\n",
    "               \n",
    "               \n",
    "            \n",
    "    #==========================================================================================================\n",
    "    # training is finished\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('Training is done.')\n",
    "    print('-----------------------------------------------------------------')\n",
    "\n",
    "    return loss_train, loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  -----  validation :  0.031802629004232585\n",
      "epoch :  1  -----  validation :  0.0166494824225083\n",
      "epoch :  2  -----  validation :  0.008740616802242585\n",
      "epoch :  3  -----  validation :  0.005369846607209183\n",
      "epoch :  4  -----  validation :  0.0042276879321434535\n",
      "epoch :  5  -----  validation :  0.004181984069873579\n"
     ]
    }
   ],
   "source": [
    "loss_t, loss_v = train(mymodel,train_set,val_set,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_t,label = 'train')\n",
    "plt.plot(loss_v,label = 'val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show result of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lxtrue = []\n",
    "lxpred = []\n",
    "mymodel.eval()      # evaluation mode\n",
    "for i,minibatch in enumerate(val_set):\n",
    "    [y, x] = minibatch            # gets the minibatch\n",
    "    x_true    = Variable(x,requires_grad=False)\n",
    "    x_init    = Variable(y,requires_grad=False)\n",
    "    x_pred = mymodel(x_init,x_init).detach()\n",
    "    lxtrue.append(x_true[0,0].numpy())\n",
    "    lxpred.append(x_pred[0,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lxpred[0])\n",
    "plt.plot(lxpred[1])\n",
    "plt.plot(lxpred[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lxtrue[0],label='true')\n",
    "plt.plot(lxpred[0],label='pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lxtrue[1],label='true')\n",
    "plt.plot(lxpred[1],label='pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lxtrue[12],label='true')\n",
    "plt.plot(lxpred[12],label='pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.BasisChangeInv(lxtrue[12]),label='true')\n",
    "plt.plot(sim.BasisChangeInv(lxpred[12]),label='pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=2*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Parameter(torch.FloatTensor([2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
