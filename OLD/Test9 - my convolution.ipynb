{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DÃ©finition d'une convolution propre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    Performs 1D convolution on images with a constant filter.\n",
    "    Attributes\n",
    "    ----------\n",
    "        kernel (torch.FloatTensor): size c*c*h*w filter\n",
    "        mode                 (str): 'single' or 'batch'\n",
    "        stride               (int): dilation factor\n",
    "        padding                   : instance of CircularPadding or torch.nn.ReplicationPad2d\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel, mode, pad_type = 'replicate', padding=0, stride=1):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            gpu                  (str): gpu id\n",
    "            kernel (torch.FloatTensor): convolution filter\n",
    "            mode                 (str): indicates if the input is a single image of a batch of images\n",
    "            pad_type             (str): padding type (default is 'circular')\n",
    "            padding              (int): padding size (default is 0)\n",
    "            stride               (int): dilation factor (default is 1)\n",
    "        \"\"\"\n",
    "        super(MyConv1d, self).__init__()\n",
    "        self.kernel   = nn.Parameter(kernel,requires_grad=False)   \n",
    "        self.mode     = mode #'single' or 'batch'\n",
    "        self.stride   = stride\n",
    "        if padding==0:\n",
    "            size_padding = int((kernel[0,0].size(0)-1)/2)\n",
    "        else:\n",
    "            size_padding = padding\n",
    "        if pad_type == 'replicate':\n",
    "            self.padding = nn.ReplicationPad1d(size_padding)\n",
    "        if pad_type == 'reflect':\n",
    "            self.padding = nn.ReflectionPad1d(size_padding)\n",
    "        if pad_type == 'zero':\n",
    "            self.padding = nn.ConstantPad1d(size_padding,0)\n",
    "            \n",
    "    def forward(self, x): \n",
    "        \"\"\"\n",
    "        Performs a 2-D circular convolution.\n",
    "        Parameters\n",
    "        ----------\n",
    "            x (torch.FloatTensor): image(s), size n*c*h*w \n",
    "        Returns\n",
    "        -------\n",
    "            (torch.FloatTensor): result of the convolution, size n*c*h*w if mode='single', \n",
    "                                 size c*h*w if mode='batch'\n",
    "        \"\"\"\n",
    "        if self.mode == 'single':\n",
    "            return F.conv1d(self.padding(x.unsqueeze(0)), self.kernel, stride=self.stride).data[0]\n",
    "        if self.mode == 'batch':\n",
    "            return F.conv1d(self.padding(x.data), self.kernel, stride=self.stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7648, -0.6076,  0.0464, -1.0189]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((1,1,20))\n",
    "kernel = torch.FloatTensor(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyConv1d(kernel, 'single', pad_type = 'zero', padding=0, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8153, -0.8153, -0.8153]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0767)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0767)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:6].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1086)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,1:].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ma convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4\n",
    "xi = np.linspace(0,1,n)\n",
    "a=1\n",
    "kernel = xi**(a-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.33333333, 0.66666667, 1.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    k[i,:i+1] = kernel[:i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=torch.FloatTensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0319,  0.3385, -0.3518,  1.0767]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x.unsqueeze(0),k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0319,  0.3704, -0.6903,  1.4285]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    Performs 1D convolution with kernel\n",
    "    Attributes\n",
    "    ----------\n",
    "        kernel (torch.FloatTensor): size c*c*h*w filter\n",
    "        mode                 (str): 'single' or 'batch'\n",
    "        stride               (int): dilation factor\n",
    "        padding                   : instance of CircularPadding or torch.nn.ReplicationPad2d\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel, mode):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            gpu                  (str): gpu id\n",
    "            kernel (torch.FloatTensor): convolution filter\n",
    "            mode                 (str): indicates if the input is a single image of a batch of images\n",
    "            pad_type             (str): padding type (default is 'circular')\n",
    "            padding              (int): padding size (default is 0)\n",
    "            stride               (int): dilation factor (default is 1)\n",
    "        \"\"\"\n",
    "        super(MyConv1d, self).__init__()\n",
    "        self.kernel   = nn.Parameter(kernel.T,requires_grad=False)   \n",
    "        self.mode     = mode #'single' or 'batch'\n",
    "            \n",
    "    def forward(self, x): \n",
    "        \"\"\"\n",
    "        Performs convolution.\n",
    "        Parameters\n",
    "        ----------\n",
    "            x (torch.FloatTensor): image(s), size n*c*h*w \n",
    "        Returns\n",
    "        -------\n",
    "            (torch.FloatTensor): result of the convolution, size n*c*h*w if mode='single', \n",
    "                                 size c*h*w if mode='batch'\n",
    "        \"\"\"\n",
    "        if self.mode == 'single':\n",
    "            return torch.matmul(x.unsqueeze(0),self.kernel).data[0]\n",
    "        if self.mode == 'batch':\n",
    "            return torch.matmul(x.data,self.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    " m = MyConv1d(torch.FloatTensor(k),'single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8153, -1.5801, -0.9725, -1.0189]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = torch.randn((10,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MyConv1d(torch.FloatTensor(k),'batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7100,  1.3059,  1.8033, -0.3682]],\n",
       "\n",
       "        [[-0.3770, -1.4885,  0.1213, -0.3180]],\n",
       "\n",
       "        [[-0.1910, -1.3440, -1.5387, -2.0038]],\n",
       "\n",
       "        [[-1.5182, -1.3060,  0.1131, -1.1023]],\n",
       "\n",
       "        [[ 1.0715,  0.8020, -0.0766,  0.3836]],\n",
       "\n",
       "        [[ 3.2560,  1.9025,  2.8441,  1.2860]],\n",
       "\n",
       "        [[-3.5118, -3.5939, -2.5407, -0.4437]],\n",
       "\n",
       "        [[-1.0441, -1.4403, -1.7088, -1.2483]],\n",
       "\n",
       "        [[-0.4146, -0.0804, -0.3606,  0.3237]],\n",
       "\n",
       "        [[-3.3132, -1.2709,  0.1289, -1.7600]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm(xm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4041, -0.4975,  2.1715, -0.3682]],\n",
       "\n",
       "        [[ 1.1115, -1.6097,  0.4393, -0.3180]],\n",
       "\n",
       "        [[ 1.1530,  0.1947,  0.4651, -2.0038]],\n",
       "\n",
       "        [[-0.2122, -1.4191,  1.2154, -1.1023]],\n",
       "\n",
       "        [[ 0.2694,  0.8786, -0.4602,  0.3836]],\n",
       "\n",
       "        [[ 1.3535, -0.9415,  1.5580,  1.2860]],\n",
       "\n",
       "        [[ 0.0821, -1.0533, -2.0970, -0.4437]],\n",
       "\n",
       "        [[ 0.3962,  0.2685, -0.4605, -1.2483]],\n",
       "\n",
       "        [[-0.3343,  0.2802, -0.6842,  0.3237]],\n",
       "\n",
       "        [[-2.0423, -1.3998,  1.8888, -1.7600]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xm.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 4])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xm.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 4])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xm.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
